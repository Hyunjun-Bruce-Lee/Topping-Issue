{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22a34af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268\n",
      "12514\n",
      "10003_301\n",
      "10003_601\n",
      "10003_1501\n",
      "10003_2101\n",
      "10003_2401\n",
      "10003_2701\n",
      "10003_3301\n",
      "10003_3901\n",
      "10003_4201\n",
      "10003_4501\n",
      "10003_5101\n",
      "10003_5401\n",
      "10003_5701\n",
      "10003_6001\n",
      "10003_6301\n",
      "10003_6601\n",
      "10003_6901\n",
      "10003_7201\n",
      "10003_8101\n",
      "10003_8701\n",
      "10003_9301\n",
      "10003_9601\n",
      "10003_10201\n",
      "10003_10801\n",
      "10003_11101\n",
      "10003_12001\n",
      "10003_12301\n",
      "               ID        Date                                           Title  \\\n",
      "0        10003_12  2021-05-01        美 전문가들, 바이든 행정부 새 대북정책에 '회의적'…\"이미 실패한 길\"   \n",
      "1        10003_15  2021-05-01             '트럼프도 오바마도 아닌' 바이든式 대북정책..北 호응에 달렸다   \n",
      "2        10003_16  2021-05-01               北 선전매체 \"대북 전단 대신 '탈북자 쓰레기'날려라\" 비판   \n",
      "3        10003_20  2021-05-01             \"조정되고 실용적인 접근\"…바이든표 대북 정책 어떤 내용 담길까   \n",
      "4        10003_21  2021-05-01  美 연습기 조립서 KF-21까지… 100년 만에 편 ‘자주국방 날개’ [S 스토리]   \n",
      "...           ...         ...                                             ...   \n",
      "9467  10003_12508  2021-08-31                 한미, 美서 북핵 후속 협의…성김 \"北 답변 듣길 기대\"   \n",
      "9468  10003_12510  2021-08-31                 美, 북한 핵시설 재가동설에 \"대화와 외교 긴급성 강조\"   \n",
      "9469  10003_12512  2021-08-31              윤봉길 의사 고향 ‘충남 예산군’, 올해 독립유공자 최다 배출   \n",
      "9470  10003_12513  2021-08-31                        北리룡남·中공안부장 만나 접경지역 안정 논의   \n",
      "9471  10003_12514  2021-08-31                           하노이 굴욕 김정은, 바이든에 앙갚음?   \n",
      "\n",
      "                                                Content  Content_len  \\\n",
      "0     \\n\\n\\n\\n\\n바이든 행정부, '단계적 접근법' 내용 담은 새 대북정책 검토 완...       1286.0   \n",
      "1     \\n\\n\\n\\n\\n완전한 비핵화 목표, 실용적 접근…트럼프·오바마식 '절충'WP 美...       1778.0   \n",
      "2     \\n\\n\\n\\n\\n탈북민 단체 대북 전단 살포에 \"쓰레기\" 발끈\"마음 편히 살려면 ...        830.0   \n",
      "3     \\n\\n\\n\\n\\n'빅딜-전략적 인내' 균형…리비아식 모델 배제할 듯동맹 협력 통한...       2989.0   \n",
      "4     \\n\\n\\n\\n\\n\"우리 손으로 영공 수호\"… 국산 전투기 개발史1920년 美에 한...       5684.0   \n",
      "...                                                 ...          ...   \n",
      "9467  \\n\\n\\n\\n\\n노규덕 한반도평화교섭본부장, 성김 美대북특별대표와 협의노규덕 한반...       1379.0   \n",
      "9468  \\n\\n\\n\\n\\n기사내용 요약\"북한과 대화 계속 모색할 것\"[AP/뉴시스] 3월2...        742.0   \n",
      "9469  \\n\\n\\n\\n\\n국가보훈처, 31일 독립유공자 포상 전수식 개최    세종시 어진...        695.0   \n",
      "9470  \\n\\n\\n\\n\\n기사내용 요약베이징서 회담…북중 실질적 협력 강화 강조[베이징/신...        484.0   \n",
      "9471  \\n\\n\\n\\n\\n\\t\\n\\t  조 바이든 미국 행정부의 대화 제안에 불응하던 북한...       1308.0   \n",
      "\n",
      "                                                Comment  Comment_cnt  \\\n",
      "0     [[\"후세인처럼 김정은과 그 집 개를 제거하는 것만이 유일한 핵 폐기 방법\", 98...         53.0   \n",
      "1     [[\"이처럼 외부환경이 변해가는데 문재인 대통령은 여전히 싱가포르의 기적을 외치며 ...         13.0   \n",
      "2     [[\"저렇게 발광하는건 대북전단이 효과가 있다는 증거....\\n계속해서 보내서 북한...         38.0   \n",
      "3                                                    NA          0.0   \n",
      "4     [[\"무기의 국산화가 왜중요한지는 k9자주포 한가지만 봐도 알수있는것이지. 국산화에...         35.0   \n",
      "...                                                 ...          ...   \n",
      "9467  [[\"현대로템 가쥬아\", 1.0, 1.0], [\"쇼를 해라\", 0.0, 0.0], ...          3.0   \n",
      "9468  [[\"췁췁이가 핵인질로 살기위한 기반을 마련했으니 다음 대통은 누가되던 북한에서 날...          2.0   \n",
      "9469                                                 NA          0.0   \n",
      "9470  [[\"탈북 난민 인정 안하는 인권 유린 나라 중국!  UN은 중국 인권 유린 제재 ...          2.0   \n",
      "9471  [[\"미국의 인내심에도 한계가 왔을지 모르겠다 문재인무시하고 언제 김정은관사와 노동...          4.0   \n",
      "\n",
      "                                              Sentiment  \\\n",
      "0     {'좋아요': 45, '훈훈해요': 0, '슬퍼요': 0, '화나요': 16, '후...   \n",
      "1     {'좋아요': 20, '훈훈해요': 0, '슬퍼요': 0, '화나요': 8, '후속...   \n",
      "2     {'좋아요': 4, '훈훈해요': 0, '슬퍼요': 0, '화나요': 89, '후속...   \n",
      "3     {'좋아요': 1, '훈훈해요': 0, '슬퍼요': 0, '화나요': 0, '후속기...   \n",
      "4     {'좋아요': 79, '훈훈해요': 10, '슬퍼요': 1, '화나요': 6, '후...   \n",
      "...                                                 ...   \n",
      "9467  {'좋아요': 0, '훈훈해요': 0, '슬퍼요': 0, '화나요': 1, '후속기...   \n",
      "9468  {'좋아요': 0, '훈훈해요': 0, '슬퍼요': 0, '화나요': 0, '후속기...   \n",
      "9469  {'좋아요': 1, '훈훈해요': 0, '슬퍼요': 0, '화나요': 0, '후속기...   \n",
      "9470  {'좋아요': 0, '훈훈해요': 0, '슬퍼요': 0, '화나요': 0, '후속기...   \n",
      "9471  {'좋아요': 0, '훈훈해요': 0, '슬퍼요': 0, '화나요': 11, '후속...   \n",
      "\n",
      "                                                   Link Press  \n",
      "0                https://www.news1.kr/articles/?4293503   뉴스1  \n",
      "1     http://www.edaily.co.kr/news/newspath.asp?news...  이데일리  \n",
      "2     https://www.dailian.co.kr/news/view/987416/?sc...  데일리안  \n",
      "3     http://www.newsis.com/view/?id=NISX20210501_00...   뉴시스  \n",
      "4     http://www.segye.com/content/html/2021/04/30/2...  세계일보  \n",
      "...                                                 ...   ...  \n",
      "9467             https://www.news1.kr/articles/?4419217   뉴스1  \n",
      "9468  http://www.newsis.com/view/?id=NISX20210831_00...   뉴시스  \n",
      "9469  http://www.segye.com/content/html/2021/08/30/2...  세계일보  \n",
      "9470  http://www.newsis.com/view/?id=NISX20210830_00...   뉴시스  \n",
      "9471        https://www.joongang.co.kr/article/25002827  중앙일보  \n",
      "\n",
      "[9472 rows x 10 columns]\n",
      "time : 12840.821420192719\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "import re\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "category = ['268'] # 네이버 카테고리 입력\n",
    "\n",
    "dt_index = pd.date_range(start='20210806', end='20210831') # 기간 입력\n",
    "dt_list = dt_index.strftime(\"%Y%m%d\").tolist()\n",
    "\n",
    "for idx, ca in enumerate(category):\n",
    "    print(ca)\n",
    "    # url 수집\n",
    "    url_press_list = []\n",
    "    for date in dt_list:\n",
    "        \n",
    "        page_num = 1\n",
    "        last = False\n",
    "        \n",
    "        while last == False:\n",
    "            raw = requests.get(\"https://news.naver.com/main/list.naver?mode=LS2D&sid2=\"+ca+\"&mid=shm&sid1=101&date=\"+date+\"&page=\"+str(page_num),\n",
    "                                    headers={\"User-Agent\":\"Mozilla/5.0\"})\n",
    "            html = BeautifulSoup(raw.text, 'html.parser')\n",
    "\n",
    "            page = html.find('div', {'class':'paging'})\n",
    "            try:\n",
    "                page_a_list = page.findAll('a')\n",
    "\n",
    "                try:\n",
    "                    if '다음' in str(page_a_list[-1]):\n",
    "                        page_num += 10\n",
    "                    else:\n",
    "                        last = True\n",
    "                        try:\n",
    "                            page_num = int(page_a_list[-1].text)\n",
    "                        except:\n",
    "                            page_num = page_num\n",
    "                except:\n",
    "                    last = True\n",
    "                    page_num = 1\n",
    "            \n",
    "            except:\n",
    "                page_num += 10\n",
    "                \n",
    "        time.sleep(random.randrange(3,10))\n",
    "                \n",
    "\n",
    "        for i in range(1, page_num+1):  \n",
    "            raw = requests.get(\"https://news.naver.com/main/list.naver?mode=LS2D&sid2=\"+ca+\"&mid=shm&sid1=101&date=\"+date+\"&page=\"+str(i),\n",
    "                            headers={\"User-Agent\":\"Mozilla/5.0\"})\n",
    "            html = BeautifulSoup(raw.text, 'html.parser')                \n",
    "\n",
    "            news_container = html.select(\"div.list_body.newsflash_body li dl\")\n",
    "\n",
    "            for news in news_container:\n",
    "                try:\n",
    "                    url = news.select_one(\"dt:nth-child(2) a\")['href']\n",
    "                except:\n",
    "                    url = news.select_one(\"dt:nth-child(1) a\")['href']\n",
    "                \n",
    "                try:\n",
    "                    press = news.select_one(\"span.writing\").text\n",
    "                except:\n",
    "                    press = \"NA\"\n",
    "                \n",
    "                url_press_list.append([url, press])\n",
    "\n",
    "    time.sleep(random.randrange(10,15))\n",
    "    \n",
    "    print(len(url_press_list))\n",
    "    \n",
    "    # 내용 수집\n",
    "    content_list = []\n",
    "    for url_idx, url_press in enumerate(url_press_list):\n",
    "        try:\n",
    "            raw = requests.get(url_press[0], headers={\"User-Agent\":\"Mozilla/5.0\"})\n",
    "            html = BeautifulSoup(raw.text, 'html.parser')    \n",
    "\n",
    "            ID = \"100\" + ('%02d' % (idx + 3)) + \"_\" + str(url_idx + 1) # 아이디\n",
    "\n",
    "            # 날짜\n",
    "            try:\n",
    "                date = html.select_one(\"div.sponsor > span:nth-child(1)\").text\n",
    "                date = date.replace(\".\", \"-\")[:10]\n",
    "                date = datetime.strptime(date, '%Y-%m-%d').date()\n",
    "\n",
    "            except:\n",
    "                date = html.select_one(\"div.sponsor > span:nth-child(2)\").text\n",
    "                date = date.replace(\".\", \"-\")[:10]\n",
    "                date = datetime.strptime(date, '%Y-%m-%d').date()        \n",
    "\n",
    "            Date = date\n",
    "\n",
    "            Title = html.select_one('h3#articleTitle').text # 제목\n",
    "            Content = html.select_one('div#articleBodyContents').text # 내용\n",
    "            Content_len = float(len(Content)) # 내용의 길이\n",
    "\n",
    "            # 댓글\n",
    "            Comment = []\n",
    "\n",
    "            oid = url_press[0].split(\"oid=\")[1].split(\"&\")[0]\n",
    "            aid = url_press[0].split(\"aid=\")[1]\n",
    "            c_page = 1\n",
    "\n",
    "            header = {\n",
    "                \"User-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36\",\n",
    "                \"referer\": url_press[0],\n",
    "            }\n",
    "\n",
    "            while True:\n",
    "                c_url = \"https://apis.naver.com/commentBox/cbox/web_neo_list_jsonp.json?ticket=news&templateId=default_society&pool=cbox5&_callback=jQuery1707138182064460843_1523512042464&lang=ko&country=&objectId=news\" + oid + \"%2C\" + aid + \"&categoryId=&pageSize=20&indexSize=10&groupId=&listType=OBJECT&pageType=more&page=\" + str(\n",
    "                    c_page) + \"&refresh=false&sort=FAVORITE\"\n",
    "\n",
    "                c_raw = requests.get(c_url, headers=header)\n",
    "                c_html = BeautifulSoup(c_raw.content, \"html.parser\")\n",
    "                total_comm = str(c_html).split('comment\":')[1].split(\",\")[0]\n",
    "\n",
    "                c_content = re.findall('\"contents\":([^\\*]*),\"userIdNo\"', str(c_html))\n",
    "                c_like = re.findall('\"sympathyCount\":([^\\*]*),\"antipathyCount\"', str(c_html))\n",
    "                c_dislike = re.findall('\"antipathyCount\":([^\\*]*),\"hideReplyButton\"', str(c_html))\n",
    "\n",
    "                for i in range(len(c_content)):\n",
    "                    Comment.append([c_content[i], float(c_like[i]), float(c_dislike[i])])\n",
    "\n",
    "                if int(total_comm) <= ((c_page) * 20):\n",
    "                    break\n",
    "                else:\n",
    "                    c_page += 1\n",
    "\n",
    "            Comment_cnt = float(len(Comment))\n",
    "\n",
    "            if len(Comment) == 0:\n",
    "                Comment = \"NA\"\n",
    "\n",
    "            # 공감\n",
    "            Sentiment = {\"좋아요\" : 0, \"훈훈해요\" : 0, \"슬퍼요\" : 0, \"화나요\" : 0, \"후속기사 원해요\" : 0}\n",
    "\n",
    "            s_url = \"https://news.like.naver.com/v1/search/contents?suppress_response_codes=true&callback=jQuery11240039925253521598814_1631253269105&q=NEWS%5Bne_\" + oid + \"_\" + aid + \"%5D%7CNEWS_SUMMARY%5B087_0000859977%5D%7CJOURNALIST%5B75301(period)%5D%7CNEWS_MAIN%5Bne_087_0000859977%5D&isDuplication=false&_=1631253269107\"\n",
    "            s_raw = requests.get(s_url, headers=header)\n",
    "\n",
    "            idx1 = s_raw.text.find('(')\n",
    "            idx2 = s_raw.text.find(')')\n",
    "\n",
    "            s_jsonData = s_raw.text[idx1+1:idx2]\n",
    "            s_jsonData = json.loads(s_jsonData)\n",
    "\n",
    "            for i in range(len(s_jsonData['contents'][0]['reactions'])):\n",
    "                Sentiment[s_jsonData['contents'][0]['reactions'][i]['reactionTypeCode']['description']] = s_jsonData['contents'][0]['reactions'][i]['count']\n",
    "\n",
    "            Link = html.select_one(\"div.sponsor a.btn_artialoriginal\")['href'] # 링크\n",
    "            Press = url_press[1].replace(\" \", \"\") # 언론사\n",
    "            \n",
    "            content_list.append([ID, Date, Title, Content, Content_len, Comment, Comment_cnt, Sentiment, Link, Press])\n",
    "\n",
    "            if url_idx % 300 == 0:\n",
    "                time.sleep(random.randrange(30,50))\n",
    "                print(ID)\n",
    "                \n",
    "                \n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "            \n",
    "    # 파일 저장   \n",
    "    df = pd.DataFrame(content_list, columns =['ID', 'Date', 'Title', 'Content', 'Content_len', 'Comment', 'Comment_cnt', 'Sentiment', 'Link', 'Press'])\n",
    "\n",
    "    print(df)\n",
    "    with open('파일명을 입력하세요', 'wb') as f: # 저장 파일명 입력\n",
    "        pickle.dump(df, f)\n",
    "\n",
    "    f.close()\n",
    "    print(\"time :\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316a38a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
